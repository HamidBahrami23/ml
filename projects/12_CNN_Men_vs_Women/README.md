# ğŸ–¼ï¸ Simple CNN â€“ Men vs Women Classification

## ğŸ“Œ Overview
This project builds a simple convolutional neural network for binary classification of men vs women images.  
The model uses a basic CNN architecture with multiple conv layers and global average pooling, trained on the Men-Women dataset from Kaggle.

---

## ğŸ“‚ Project Structure

```
12_CNN_Men_vs_Women/
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ 12_CNN_Men_vs_Women.ipynb  # Main notebook with model implementation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ namedatset.py             # Dataset utilities
â”‚   â””â”€â”€ namedatsetwomen.py        # Additional dataset scripts
```

---

## ğŸ§  Key Concepts
- Simple CNN architecture with increasing filters
- Convolutional layers (32 â†’ 64 â†’ 128 â†’ 256 â†’ 512 filters)
- Max pooling for spatial reduction
- Global average pooling before dense layers
- Data augmentation (horizontal flip, rotation, zoom)
- Binary classification with sigmoid activation
- Adam optimizer with default learning rate

---

## âœ… Result Summary
- **Architecture**: 5 conv blocks with global average pooling
- **Input size**: 180x180 RGB images
- **Dataset**: 2000 train, 400 validation, 400 test images
- **Training epochs**: 75
- **Final performance**: Test accuracy around 80-85% (good performance for custom CNN)

Confusion Matrix:

| Class | Performance |
|-------|-------------|
| Men   | Good classification |
| Women | Good classification |

---

## ğŸ”§ Tech Stack
| Library | Usage |
|---------|--------|
| `tensorflow` / `keras` | CNN model, training |
| `matplotlib` | Visualization |
| `numpy` | Data manipulation |

---

## â–¶ï¸ How to Run

1. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
2. Launch the notebook:
   ```bash
   jupyter notebook notebook/12_CNN_Men_vs_Women.ipynb
   ```

---

## ğŸ’¡ Learnings

- Simple CNNs can achieve good performance with sufficient training
- Global average pooling reduces overfitting compared to flatten + dense
- Data augmentation significantly improves generalization
- More epochs allow better convergence but watch for overfitting

## ğŸš€ Future Improvements

- Implement early stopping and learning rate scheduling
- Add batch normalization for faster convergence
- Experiment with different architectures (ResNet blocks)
- Use transfer learning for potentially better results
- Add more sophisticated data augmentation